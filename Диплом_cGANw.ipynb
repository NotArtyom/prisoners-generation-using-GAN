{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Диплом cGANw.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==1.15.2\n",
        "!pip install numpy==1.19.5\n",
        "!pip install keras==2.3.1"
      ],
      "metadata": {
        "id": "XLVldPxyXvYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSqJV_9QCSSd"
      },
      "source": [
        "!import tensorflow\n",
        "import keras\n",
        "from IPython.display import clear_output\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "clear_output()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SiZAtQsCzsk"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt94shet-nAH"
      },
      "source": [
        "## Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPd-xXbwj2_g"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip /content/drive/MyDrive/Диплом/data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_I_P-GL-rY2"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcK6G46i-tpv"
      },
      "source": [
        "def load_data(path):\n",
        "  labels = pd.read_csv(os.path.join(path, 'labels_utf8.csv'), header=0, index_col=None, squeeze=True)\n",
        "  labels = labels[labels[\"Sex Offender\"] == True]\n",
        "  labels = labels[labels[\"Race\"] != \"Not Available\"]\n",
        "  labels = labels[labels[\"Race\"] != \"Bi-Racial\"]\n",
        "  labels = labels[[\"ID\", \"Sex\", \"Race\"]]\n",
        "  sex_to_idx = {'Female': 1, 'Male': 0}\n",
        "  race_to_idx = {'Amer Indian': 0,\n",
        "                'Asian': 0.25,\n",
        "                'Black': 0.5,\n",
        "                'Hispanic': 0.75,\n",
        "                'White': 1}\n",
        "  labels = labels.replace({\"Sex\": sex_to_idx})\n",
        "  labels = labels.replace({\"Race\": race_to_idx})\n",
        "  files = os.listdir(os.path.join(path, 'front'))\n",
        "  imgs=[]\n",
        "  for i in range(len(files)):\n",
        "    if \".DS_Store\" in files[i]:\n",
        "      continue\n",
        "    imgs.append(files[i])\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(len(imgs)):\n",
        "    front_image = Image.open(os.path.join(path, 'front/', imgs[i]))\n",
        "    front_image = front_image.convert('RGB')\n",
        "    front_image = front_image.resize((128,128))\n",
        "    front_image = np.array(front_image)\n",
        "    id = imgs[i][:6]\n",
        "    try:\n",
        "      d = labels[labels.ID == id].values.tolist()[0][1:]\n",
        "    except IndexError:\n",
        "      continue\n",
        "    X.append(front_image)\n",
        "    y.append(d)\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "def load_real_samples():\n",
        "  X, trainy = load_data(\"data/\")\n",
        "\n",
        "  X = X.astype('float32')\n",
        "  # scale from [0,255] to [-1,1]\n",
        "  X = (X - 127.5) / 127.5\n",
        "  return [X, trainy]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaOggnBI-yPs"
      },
      "source": [
        "# Model definiton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7ASCJ_pN8Zd"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from PIL import Image\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import mean\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Concatenate\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.constraints import Constraint\n",
        "from keras import backend\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-9P3tTPOD9O"
      },
      "source": [
        "## Wasserstein loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hms2PhXODX3"
      },
      "source": [
        "# clip model weights to a given hypercube\n",
        "class ClipConstraint(Constraint):\n",
        "\t# set clip value when initialized\n",
        "\tdef __init__(self, clip_value):\n",
        "\t\tself.clip_value = clip_value\n",
        " \n",
        "\t# clip model weights to hypercube\n",
        "\tdef __call__(self, weights):\n",
        "\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\n",
        " \n",
        "\t# get the config\n",
        "\tdef get_config(self):\n",
        "\t\treturn {'clip_value': self.clip_value}\n",
        " \n",
        "# calculate wasserstein loss\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "\treturn backend.mean(y_true * y_pred)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJMiipIgNbYK"
      },
      "source": [
        "## Descriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky9ORcCmN75L"
      },
      "source": [
        "def define_discriminator(in_shape=(128, 128, 3), n_classes=10):\n",
        "\n",
        "    # weight initialization\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    # weight constraint\n",
        "    const = ClipConstraint(0.01)\n",
        "\n",
        "    in_label = Input(shape=(2,))\n",
        "\n",
        "    li = Embedding(n_classes, 50)(in_label)\n",
        "\n",
        "    n_nodes = int(in_shape[0] * in_shape[1] * in_shape[2]/2)\n",
        "    li = Dense(n_nodes)(li)\n",
        "\n",
        "    li = Reshape((in_shape[0], in_shape[1], in_shape[2]))(li)\n",
        "\n",
        "    in_image = Input(shape=in_shape)\n",
        "\n",
        "    merge = Concatenate()([in_image, li])\n",
        "\n",
        "    fe = Flatten()(merge)\n",
        "    lr = LinearRegression()\n",
        "    #fe = Flatten()(fe)\n",
        "\n",
        "    fe = Dropout(0.4)(fe)\n",
        "\n",
        "    out_layer = Dense(1, activation='sigmoid')(fe)\n",
        "\n",
        "    model = Model([in_image, in_label], out_layer)\n",
        "\n",
        "    opt = RMSprop(lr=0.00005)\n",
        "    model.compile(loss=wasserstein_loss, optimizer=opt, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ5AvM94OQXM"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lWOJD9NOSxY"
      },
      "source": [
        "def define_generator(latent_dim, n_classes=10):\n",
        "    dim = 32\n",
        "\n",
        "    in_label = Input(shape=(2,))\n",
        "\n",
        "    li = Embedding(n_classes, 50)(in_label)\n",
        "\n",
        "    n_nodes = int(dim * dim/2)\n",
        "    li = Dense(n_nodes)(li)\n",
        "\n",
        "    li = Reshape((dim, dim, 1))(li)\n",
        "\n",
        "    in_lat = Input(shape=(latent_dim,))\n",
        "\n",
        "    n_nodes = 128 * dim * dim\n",
        "    gen = Dense(n_nodes)(in_lat)\n",
        "    gen = LeakyReLU(alpha=0.2)(gen)\n",
        "    gen = Reshape((dim, dim, 128))(gen)\n",
        "\n",
        "    merge = Concatenate()([gen, li])\n",
        "\n",
        "    gen = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(merge)\n",
        "    gen = LeakyReLU(alpha=0.2)(gen)\n",
        "\n",
        "    gen = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(gen)\n",
        "    gen = LeakyReLU(alpha=0.2)(gen)\n",
        "\n",
        "    out_layer = Conv2D(3, (7, 7), activation='tanh', padding='same')(gen)\n",
        "\n",
        "    model = Model([in_lat, in_label], out_layer)\n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXCzFpBcOVUR"
      },
      "source": [
        "## GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV_w7hs6OaI2"
      },
      "source": [
        "def define_gan(g_model, d_model):\n",
        "    d_model.trainable = False\n",
        "\n",
        "    gen_noise, gen_label = g_model.input\n",
        "\n",
        "    gen_output = g_model.output\n",
        "\n",
        "    gan_output = d_model([gen_output, gen_label])\n",
        "\n",
        "    model = Model([gen_noise, gen_label], gan_output)\n",
        "\n",
        "    opt = RMSprop(lr=0.00005)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l14xJGrgOmEZ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRvlDhXeO3X1"
      },
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "    images, labels = dataset\n",
        "    ix = randint(0, images.shape[0], n_samples)\n",
        "    X, labels = images[ix], labels[ix]\n",
        "    y = -ones((n_samples, 1))\n",
        "    return [X, labels], y\n",
        "\n",
        "\n",
        "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    z_input = x_input.reshape(n_samples, latent_dim)\n",
        "    labels = []\n",
        "    for i in range(n_samples):\n",
        "      new_sex = np.random.randint(n_classes)\n",
        "      new_race = np.random.uniform(0,n_classes-1,1)[0]\n",
        "      labels.append(np.array([new_sex, new_race]))\n",
        "    labels = np.array(labels)\n",
        "    return [z_input, labels]\n",
        "\n",
        "\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
        "    images = generator.predict([z_input, labels_input])\n",
        "    y = ones((n_samples, 1))\n",
        "    return [images, labels_input], y\n",
        "\n",
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d1_hist, d2_hist, g_hist):\n",
        "\t# plot history\n",
        "\tpyplot.plot(d1_hist, label='discr_real')\n",
        "\tpyplot.plot(d2_hist, label='discr_fake')\n",
        "\tpyplot.plot(g_hist, label='gen')\n",
        "\tpyplot.legend()\n",
        "\tpyplot.savefig('plot_line_plot_loss.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=600, n_batch=128):\n",
        "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
        "    half_batch = int(n_batch / 2)\n",
        "    c1_hist, c2_hist, g_hist = list(), list(), list()\n",
        "    for i in range(n_epochs):\n",
        "        for j in range(bat_per_epo):\n",
        "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
        "            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
        "            c1_hist.append(d_loss1)\n",
        "\n",
        "            [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "            d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
        "            c2_hist.append(d_loss2)\n",
        "\n",
        "            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
        "            y_gan = -ones((n_batch, 1))\n",
        "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
        "            g_hist.append(g_loss)\n",
        "\n",
        "            print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "                  (i + 1, j + 1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "    # save the generator model\n",
        "    plot_history(c1_hist, c2_hist, g_hist)\n",
        "    g_model.save('cgan_generator.h5')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUKHRQ_2X_EZ"
      },
      "source": [
        "latent_dim = 100\n",
        "\n",
        "d_model = define_discriminator()\n",
        "\n",
        "g_model = define_generator(latent_dim)\n",
        "\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "\n",
        "dataset = load_real_samples()\n",
        "\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=300, n_batch=128 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3lhsmZpO8aD"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVrpJwRsVbS9"
      },
      "source": [
        "from numpy import asarray\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.models import load_model\n",
        "from matplotlib import pyplot\n",
        "\n",
        "model = load_model('cgan_generator.h5')\n",
        "\n",
        "n_samples = 3\n",
        "latent_dim=100\n",
        "labels = np.array([np.array([1, 0])])\n",
        "\n",
        "x_input = randn(latent_dim * n_samples)\n",
        "z_input = x_input.reshape(n_samples, latent_dim)\n",
        "\n",
        "X  = model.predict([z_input, labels])\n",
        "X = (X + 1) / 2.0\n",
        "\n",
        "plt.imshow(X[0, :, :, :])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}